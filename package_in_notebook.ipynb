{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP github repository\n",
    "\n",
    "for interactive use\n",
    "\n",
    "Modified version of:\n",
    "https://github.com/HarshdeepGupta/recommender_pytorch/blob/master/MLP.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Python imports\n",
    "import argparse\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Workspace imports\n",
    "from src.evaluate import evaluate_model\n",
    "from src.Dataset import MovieLensDataset\n",
    "from src.utils import train_one_epoch, test, plot_statistics\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args_dict = {\n",
    "    \"path\": \"data/\",\n",
    "    \"dataset\": \"movielens\",\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size\": 256,\n",
    "    \"layers\": [16, 32, 16, 8],\n",
    "    'weight_decay': 0.00001,\n",
    "    \"num_neg_train\": 4, #'Number of negative instances to pair \n",
    "                        #with a positive instance while training'\n",
    "    \"num_neg_test\": 100,\n",
    "    \"lr\": 0.001,\n",
    "    \"dropout\": 0.,\n",
    "    \"learner\": \"adam\",\n",
    "    \"verbose\": 1,\n",
    "    \"out\": 1 #save trained model or not\n",
    "}\n",
    "\n",
    "args = default_args_dict\n",
    "path = args[\"path\"]\n",
    "dataset = args[\"dataset\"]\n",
    "layers = args[\"layers\"]\n",
    "weight_decay = args[\"weight_decay\"]\n",
    "num_negatives_train = args[\"num_neg_train\"]\n",
    "num_negatives_test = args[\"num_neg_test\"]\n",
    "dropout = args[\"dropout\"]\n",
    "learner = args[\"learner\"]\n",
    "learning_rate = args[\"lr\"]\n",
    "batch_size = args[\"batch_size\"]\n",
    "epochs = args[\"epochs\"]\n",
    "verbose = args[\"verbose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP arguments: {'path': 'data/', 'dataset': 'movielens', 'epochs': 30, 'batch_size': 256, 'layers': [16, 32, 16, 8], 'weight_decay': 1e-05, 'num_neg_train': 4, 'num_neg_test': 100, 'lr': 0.001, 'dropout': 0.0, 'learner': 'adam', 'verbose': 1, 'out': 1} \n"
     ]
    }
   ],
   "source": [
    "topK = 10\n",
    "print(\"MLP arguments: %s \" % (args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO:\n",
    "\n",
    "+ Create a MovieLensDataSet object for other datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used methods/attributes or MovieLensDataset:\n",
    "\n",
    "+ trainMatrix, testRatings, testNegatives\n",
    "+ DataLoader takes it as argument of DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data done [4.9 s]. #user=944, #item=1683, #train=99057, #test=943\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "t1 = time()\n",
    "full_dataset = MovieLensDataset(\n",
    "    path + dataset, num_negatives_train=num_negatives_train,\n",
    "    num_negatives_test=num_negatives_test)\n",
    "train, testRatings, testNegatives = (full_dataset.trainMatrix,\n",
    "                                     full_dataset.testRatings, full_dataset.testNegatives)\n",
    "num_users, num_items = train.shape\n",
    "print(\"Load data done [%.1f s]. #user=%d, #item=%d, #train=%d, #test=%d\"\n",
    "      % (time()-t1, num_users, num_items, train.nnz, len(testRatings)))\n",
    "\n",
    "training_data_generator = DataLoader(\n",
    "    full_dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, n_users, n_items, layers=[16, 8], dropout=False):\n",
    "        \"\"\"\n",
    "        Simple Feedforward network with Embeddings for users and items\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert (layers[0] % 2 == 0), \"layers[0] must be an even number\"\n",
    "        self.__alias__ = \"MLP {}\".format(layers)\n",
    "        self.__dropout__ = dropout\n",
    "\n",
    "        # user and item embedding layers\n",
    "        embedding_dim = int(layers[0]/2)\n",
    "        self.user_embedding = torch.nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = torch.nn.Embedding(n_items, embedding_dim)\n",
    "\n",
    "        # list of weight matrices\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        # hidden dense layers\n",
    "        for _, (in_size, out_size) in enumerate(zip(layers[:-1], layers[1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "        # final prediction layer\n",
    "        self.output_layer = torch.nn.Linear(layers[-1], 1)\n",
    "\n",
    "    def forward(self, feed_dict):\n",
    "        users = feed_dict['user_id']\n",
    "        items = feed_dict['item_id']\n",
    "        user_embedding = self.user_embedding(users)\n",
    "        item_embedding = self.item_embedding(items)\n",
    "        # concatenate user and item embeddings to form input\n",
    "        x = torch.cat([user_embedding, item_embedding], 1)\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            x = self.fc_layers[idx](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x,  p=self.__dropout__, training=self.training)\n",
    "        logit = self.output_layer(x)\n",
    "        rating = torch.sigmoid(logit)\n",
    "        return rating\n",
    "\n",
    "    def predict(self, feed_dict):\n",
    "        # return the score, inputs and outputs are numpy arrays\n",
    "        for key in feed_dict:\n",
    "            if type(feed_dict[key]) != type(None):\n",
    "                feed_dict[key] = torch.from_numpy(\n",
    "                    feed_dict[key]).to(dtype=torch.long, device=device)\n",
    "        output_scores = self.forward(feed_dict)\n",
    "        return output_scores.cpu().detach().numpy()\n",
    "\n",
    "    def get_alias(self):\n",
    "        return self.__alias__\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (user_embedding): Embedding(944, 8)\n",
      "  (item_embedding): Embedding(1683, 8)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (1): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MLP(num_users, num_items, layers=layers, dropout=dropout)\n",
    "model.to(device)\n",
    "if verbose:\n",
    "    print(model)\n",
    "    \n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay)\n",
    "\n",
    "# Record performance\n",
    "hr_list = []\n",
    "ndcg_list = []\n",
    "BCE_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: HR = 0.0859, NDCG = 0.0376 [0.7 s]\n",
      "Epoch = 0\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.4507988940529737\n",
      "Eval: HR = 0.4019, NDCG = 0.2012 [0.7 s]\n",
      "Epoch = 1\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.3650287753081753\n",
      "Eval: HR = 0.3934, NDCG = 0.2147 [0.7 s]\n",
      "Epoch = 2\n",
      "Epoch completed 5.9 s\n",
      "Train Loss: 0.3579750397870707\n",
      "Eval: HR = 0.4062, NDCG = 0.2178 [0.7 s]\n",
      "Epoch = 3\n",
      "Epoch completed 6.1 s\n",
      "Train Loss: 0.3544639602650044\n",
      "Eval: HR = 0.4008, NDCG = 0.2149 [0.7 s]\n",
      "Epoch = 4\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.3514424908992856\n",
      "Eval: HR = 0.3977, NDCG = 0.2159 [0.7 s]\n",
      "Epoch = 5\n",
      "Epoch completed 5.9 s\n",
      "Train Loss: 0.34860661123766146\n",
      "Eval: HR = 0.4019, NDCG = 0.2192 [0.7 s]\n",
      "Epoch = 6\n",
      "Epoch completed 5.9 s\n",
      "Train Loss: 0.34537755880090926\n",
      "Eval: HR = 0.4295, NDCG = 0.2374 [0.7 s]\n",
      "Epoch = 7\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.3411040868870048\n",
      "Eval: HR = 0.4571, NDCG = 0.2561 [0.7 s]\n",
      "Epoch = 8\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.3353244619083035\n",
      "Eval: HR = 0.4740, NDCG = 0.2646 [0.7 s]\n",
      "Epoch = 9\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.3288544336877744\n",
      "Eval: HR = 0.4984, NDCG = 0.2748 [0.7 s]\n",
      "Epoch = 10\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.3232186744379443\n",
      "Eval: HR = 0.5048, NDCG = 0.2814 [0.7 s]\n",
      "Epoch = 11\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.31863179785182616\n",
      "Eval: HR = 0.5164, NDCG = 0.2844 [0.7 s]\n",
      "Epoch = 12\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.31477257098800454\n",
      "Eval: HR = 0.5270, NDCG = 0.2906 [0.7 s]\n",
      "Epoch = 13\n",
      "Epoch completed 6.1 s\n",
      "Train Loss: 0.31160104075297523\n",
      "Eval: HR = 0.5249, NDCG = 0.2936 [0.7 s]\n",
      "Epoch = 14\n",
      "Epoch completed 6.1 s\n",
      "Train Loss: 0.30911857783024316\n",
      "Eval: HR = 0.5440, NDCG = 0.3025 [0.7 s]\n",
      "Epoch = 15\n",
      "Epoch completed 6.2 s\n",
      "Train Loss: 0.3067989879030282\n",
      "Eval: HR = 0.5366, NDCG = 0.2980 [0.7 s]\n",
      "Epoch = 16\n",
      "Epoch completed 6.1 s\n",
      "Train Loss: 0.30481101366130575\n",
      "Eval: HR = 0.5398, NDCG = 0.3027 [0.7 s]\n",
      "Epoch = 17\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.30285695792014594\n",
      "Eval: HR = 0.5408, NDCG = 0.3023 [0.7 s]\n",
      "Epoch = 18\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.3008469134954211\n",
      "Eval: HR = 0.5419, NDCG = 0.3070 [0.7 s]\n",
      "Epoch = 19\n",
      "Epoch completed 6.1 s\n",
      "Train Loss: 0.29859642864659774\n",
      "Eval: HR = 0.5429, NDCG = 0.3060 [0.7 s]\n",
      "Epoch = 20\n",
      "Epoch completed 6.1 s\n",
      "Train Loss: 0.2966107523641537\n",
      "Eval: HR = 0.5366, NDCG = 0.3063 [0.7 s]\n",
      "Epoch = 21\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.2945714708677558\n",
      "Eval: HR = 0.5557, NDCG = 0.3132 [0.7 s]\n",
      "Epoch = 22\n",
      "Epoch completed 6.1 s\n",
      "Train Loss: 0.29234976367278925\n",
      "Eval: HR = 0.5536, NDCG = 0.3177 [0.7 s]\n",
      "Epoch = 23\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.29028300930979334\n",
      "Eval: HR = 0.5493, NDCG = 0.3105 [0.7 s]\n",
      "Epoch = 24\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.2883655822169257\n",
      "Eval: HR = 0.5589, NDCG = 0.3126 [0.7 s]\n",
      "Epoch = 25\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.2863169873946705\n",
      "Eval: HR = 0.5652, NDCG = 0.3155 [0.7 s]\n",
      "Epoch = 26\n",
      "Epoch completed 6.1 s\n",
      "Train Loss: 0.28451910696596444\n",
      "Eval: HR = 0.5620, NDCG = 0.3178 [0.7 s]\n",
      "Epoch = 27\n",
      "Epoch completed 6.1 s\n",
      "Train Loss: 0.282778836867606\n",
      "Eval: HR = 0.5567, NDCG = 0.3119 [0.7 s]\n",
      "Epoch = 28\n",
      "Epoch completed 6.1 s\n",
      "Train Loss: 0.28127818702111257\n",
      "Eval: HR = 0.5684, NDCG = 0.3159 [0.7 s]\n",
      "Epoch = 29\n",
      "Epoch completed 6.0 s\n",
      "Train Loss: 0.27966246357721875\n",
      "Eval: HR = 0.5652, NDCG = 0.3155 [0.7 s]\n",
      "hr for epochs:  [0.08589607635206786, 0.4019088016967126, 0.3934252386002121, 0.4061505832449629, 0.40084835630965004, 0.39766702014846234, 0.4019088016967126, 0.42948038176033937, 0.45705196182396607, 0.4740190880169671, 0.4984093319194062, 0.5047720042417816, 0.5164369034994698, 0.5270413573700954, 0.5249204665959704, 0.5440084835630965, 0.5365853658536586, 0.5397667020148462, 0.5408271474019088, 0.5418875927889714, 0.542948038176034, 0.5365853658536586, 0.5556733828207847, 0.5535524920466596, 0.5493107104984093, 0.5588547189819725, 0.5652173913043478, 0.5620360551431601, 0.5567338282078473, 0.5683987274655355, 0.5652173913043478]\n",
      "ndcg for epochs:  [0.03760868205923501, 0.2012127150265652, 0.2147218084321805, 0.217808315257568, 0.21490771815491824, 0.21591810696892633, 0.21917205191907027, 0.2373915619257196, 0.25605843449332244, 0.26458023111665374, 0.27484068541349954, 0.2814488209763082, 0.2843818693861067, 0.29058127328548783, 0.29357039946294394, 0.3024770543288577, 0.29801856539794025, 0.3027446625859351, 0.30225244309620947, 0.30697883311553364, 0.30603790617346516, 0.3063434370834329, 0.3132228849629237, 0.3176769120689523, 0.3104885161566025, 0.31263616988836457, 0.31553157254807696, 0.3177622958233307, 0.31194390322889964, 0.3159255606655605, 0.3155000630488305]\n",
      "loss for epochs:  [1, 0.4507988940529737, 0.3650287753081753, 0.3579750397870707, 0.3544639602650044, 0.3514424908992856, 0.34860661123766146, 0.34537755880090926, 0.3411040868870048, 0.3353244619083035, 0.3288544336877744, 0.3232186744379443, 0.31863179785182616, 0.31477257098800454, 0.31160104075297523, 0.30911857783024316, 0.3067989879030282, 0.30481101366130575, 0.30285695792014594, 0.3008469134954211, 0.29859642864659774, 0.2966107523641537, 0.2945714708677558, 0.29234976367278925, 0.29028300930979334, 0.2883655822169257, 0.2863169873946705, 0.28451910696596444, 0.282778836867606, 0.28127818702111257, 0.27966246357721875]\n"
     ]
    }
   ],
   "source": [
    "# Check Init performance\n",
    "hr, ndcg = test(model, full_dataset, topK)\n",
    "hr_list.append(hr)\n",
    "ndcg_list.append(ndcg)\n",
    "BCE_loss_list.append(1)\n",
    "# do the epochs now\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = train_one_epoch(model, training_data_generator,\n",
    "                                 loss_fn, optimizer, epoch, device)\n",
    "\n",
    "    if epoch % verbose == 0:\n",
    "        hr, ndcg = test(model, full_dataset, topK)\n",
    "        hr_list.append(hr)\n",
    "        ndcg_list.append(ndcg)\n",
    "        BCE_loss_list.append(epoch_loss)\n",
    "        # if hr > best_hr:\n",
    "        #     best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "        #     if args.out > 0:\n",
    "        #         model.save(model_out_file, overwrite=True)\n",
    "print(\"hr for epochs: \", hr_list)\n",
    "print(\"ndcg for epochs: \", ndcg_list)\n",
    "print(\"loss for epochs: \", BCE_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spike_basicoV5]",
   "language": "python",
   "name": "conda-env-spike_basicoV5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
