{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit with text in PyTorch\n",
    "\n",
    "The objective is to train an model for product/customer implicit data that takes into account characteristics of the products (particularly text). The encoding layer would then be used to address the cold start problem\n",
    "\n",
    "+ Step 1: Implement a simple implicit model in Pytorch\n",
    "+ Step 2: Add a layer that encodes text\n",
    "+ Step 3: add other product characteristics\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Python imports\n",
    "import argparse\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From https://www.ethanrosenthal.com/2017/06/20/matrix-factorization-in-pytorch/\n",
    "import numpy as np\n",
    "from scipy.sparse import rand as sprand\n",
    "import torch\n",
    "\n",
    "# Make up some random explicit feedback ratings\n",
    "# and convert to a numpy array\n",
    "n_users = 1000\n",
    "n_items = 1000\n",
    "ratings = sprand(n_users, n_items, \n",
    "                 density=0.01, format='csr')\n",
    "ratings.data = (np.random.randint(1, 5, \n",
    "                                  size=ratings.nnz)\n",
    "                          .astype(np.float64))\n",
    "ratings = ratings.toarray()\n",
    "\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        return (self.user_factors(user) * self.item_factors(item)).sum(1)\n",
    "\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=20)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr=1e-6)#, weight_decay=1e-5)#Con regularizaci√≥n\n",
    "\n",
    "# Sort our data\n",
    "rows, cols = ratings.nonzero()\n",
    "p = np.random.permutation(len(rows))\n",
    "rows, cols = rows[p], cols[p]\n",
    "\n",
    "for row, col in zip(*(rows, cols)):\n",
    "    # Turn data into tensors\n",
    "    rating = torch.FloatTensor([ratings[row, col]])\n",
    "    row = torch.LongTensor([row])\n",
    "    col = torch.LongTensor([col])\n",
    "    \n",
    "    # Predict and calculate loss\n",
    "    prediction = model(row, col)\n",
    "    loss = loss_func(prediction, rating)\n",
    "    \n",
    "    # Backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another implicit implementation:\n",
    "#https://github.com/maciejkula/spotlight/blob/master/spotlight/factorization/implicit.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From https://github.com/HarshdeepGupta/recommender_pytorch/blob/master/MLP.py\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, n_users, n_items, layers=[16, 8], dropout=False):\n",
    "        \"\"\"\n",
    "        Simple Feedforward network with Embeddings for users and items\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert (layers[0] % 2 == 0), \"layers[0] must be an even number\"\n",
    "        self.__alias__ = \"MLP {}\".format(layers)\n",
    "        self.__dropout__ = dropout\n",
    "\n",
    "        # user and item embedding layers\n",
    "        embedding_dim = int(layers[0]/2)\n",
    "        self.user_embedding = torch.nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = torch.nn.Embedding(n_items, embedding_dim)\n",
    "\n",
    "        # list of weight matrices\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        # hidden dense layers\n",
    "        for _, (in_size, out_size) in enumerate(zip(layers[:-1], layers[1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "        # final prediction layer\n",
    "        self.output_layer = torch.nn.Linear(layers[-1], 1)\n",
    "\n",
    "    def forward(self, feed_dict):\n",
    "        users = feed_dict['user_id']\n",
    "        items = feed_dict['item_id']\n",
    "        user_embedding = self.user_embedding(users)\n",
    "        item_embedding = self.item_embedding(items)\n",
    "        # concatenate user and item embeddings to form input\n",
    "        x = torch.cat([user_embedding, item_embedding], 1)\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            x = self.fc_layers[idx](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x,  p=self.__dropout__, training=self.training)\n",
    "        logit = self.output_layer(x)\n",
    "        rating = torch.sigmoid(logit)\n",
    "        return rating\n",
    "\n",
    "    def predict(self, feed_dict):\n",
    "        # return the score, inputs and outputs are numpy arrays\n",
    "        for key in feed_dict:\n",
    "            if type(feed_dict[key]) != type(None):\n",
    "                feed_dict[key] = torch.from_numpy(\n",
    "                    feed_dict[key]).to(dtype=torch.long, device=device)\n",
    "        output_scores = self.forward(feed_dict)\n",
    "        return output_scores.cpu().detach().numpy()\n",
    "\n",
    "    def get_alias(self):\n",
    "        return self.__alias__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spike_basicoV5]",
   "language": "python",
   "name": "conda-env-spike_basicoV5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
