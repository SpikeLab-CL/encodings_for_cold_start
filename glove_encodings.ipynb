{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove or Spacy encodings\n",
    "\n",
    "Takes text inputs of varying lengths and outputs glove encodings of the same length\n",
    "\n",
    "1. Tokenize with Spacy\n",
    "2. Get word embeddings (start with Spacy's, then use Glove if needed)\n",
    "3. Let torch handle uneven text lengths with `pad_sequence`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/local/anaconda3/envs/spike_basicoV5/bin/python -m spacy download en_core_web_sm\n",
    "#!/usr/local/anaconda3/envs/spike_basicoV5/bin/python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', )\n",
    "\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "banana True 6.700014 False\n",
      "afskfsd False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "tokens = nlp(\"dog cat banana afskfsd\")\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_list = [\"hiya, what's up?\",\n",
    "               \"another description of stuff\",\n",
    "               \"and a final one! Yay!\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3758096384178, 1563368096057,  244813136091, 3186865734196,\n",
       "       3874060501017,  764504178876, 3874060501017,  764504178876,\n",
       "       3874060501017,  764504178876])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.empty(10, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'another description of stuff xxxpad xxxpad xxxpad'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_list[1] + ' xxxpad'*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence(list_of_text, nlp_model, pad_text=\"xxxpad\",\n",
    "                   n_of_dims=300):\n",
    "    \"\"\"\n",
    "    Encodes a list of text with an nlp_model\n",
    "    Pads text with a string so they all have the same length\n",
    "    \"\"\"\n",
    "    max_length = 0\n",
    "    n_of_sentences = len(list_of_text)\n",
    "    lengths = np.empty(n_of_sentences, dtype='int')\n",
    "    for i, sentence in enumerate(list_of_text):\n",
    "        tokens = nlp_model(sentence)\n",
    "        lengths[i] = len(tokens)\n",
    "        max_length = max(max_length, len(tokens))\n",
    "    \n",
    "    array_of_encodings = np.empty((len(list_of_text), max_length, n_of_dims))\n",
    "    \n",
    "    for i, sentence in enumerate(list_of_text):\n",
    "        #pad text\n",
    "        sentence += (' ' + pad_text)*(max_length - lengths[i])\n",
    "        tokens = nlp(sentence)\n",
    "        array_of_encodings[i, :, :] = np.array([token.vector for token in tokens])\n",
    "\n",
    "    return array_of_encodings\n",
    "    \n",
    "encodings_of_all_sentences = encode_sequence(example_list, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Padding with pytorch instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 3, 300])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "a = torch.ones(25, 300)\n",
    "b = torch.ones(22, 300)\n",
    "c = torch.ones(15, 300)\n",
    "pad_sequence([a, b, c]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spike_basicoV5]",
   "language": "python",
   "name": "conda-env-spike_basicoV5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
